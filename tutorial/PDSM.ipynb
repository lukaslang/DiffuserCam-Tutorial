{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deblurring with a Primal-Dual Splitting Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\newcommand{\\abs}[1]{\\lvert#1\\rvert}\n",
    "\\newcommand{\\norm}[1]{\\lVert#1\\rVert}\n",
    "\\newcommand{\\lnorm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "% Numbers.\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\N}{\\mathbb{N}}\n",
    "% Math operators.\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\DeclareMathOperator*{\\Div}{div}\n",
    "$\n",
    "\n",
    "The resulting minimisation problems are of the general form\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\hat{x} \\in \\argmin_{x \\in X} \\; f(x) + g(x) + h(Kx).\n",
    "\\label{eq:minprob}\n",
    "\\end{equation}\n",
    "\n",
    "We assume that\n",
    "* $f: X \\to \\R$ is convex, differentiable on $X$, and its gradient $\\nabla f$ is $\\beta$-Lipschitz continuous.\n",
    "* $g: X \\to \\R \\cup \\{+\\infty\\}$ and $h: Y \\to \\R \\cup \\{+\\infty\\}$ are proper, convex, and lower-semicontinuous simple functions.\n",
    "* $K: X \\to Y$ is a bounded linear operator between finite-dimensional real Hilbert spaces $X$ and $Y$ with adjoint $K^{*}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding saddle point formulation reads\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\text{Find} \\, (\\hat{x}, \\hat{y}) \\in \\argmin_{x \\in X} \\max_{y \\in \\mathrm{dom}(h^{*})} \\; f(x) + g(x) - h^{*}(y) + \\langle Kx, y \\rangle.\n",
    "\\label{eq:saddlepointprob}\n",
    "\\end{equation}\n",
    "\n",
    "Here, $h^{*}: Y^{*} \\to \\R \\cup \\{+ \\infty\\}$ is the Legendre--Fenchel conjugate of $h$ and $Y^{*}$ denotes the dual space of $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem can be solved by means of the primal-dual hybrid gradient (PDHG) algorithm \\cite{ChaPoc11}, \n",
    "\n",
    "Condat, L. A Primalâ€“Dual Splitting Method for Convex Optimization Involving Lipschitzian, Proximable and Linear Composite Terms. J. Optim. Theory Appl., 158:460, 2013.\n",
    "\n",
    "See https://doi.org/10.1007/s10957-012-0245-9.\n",
    "\n",
    "It consists of iterating\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "\\begin{aligned}\n",
    "    \\tilde{y}^{(k + 1)} & = \\mathrm{prox}_{\\sigma h^{*}} \\Bigl( y^{(k)} + \\sigma Kx^{(k)} \\Bigr), \\\\\n",
    "    \\tilde{x}^{(k + 1)} & = \\mathrm{prox}_{\\tau g} \\Bigl( x^{(k)} + \\tau \\nabla f(x^{(k)}) - \\tau K^{*} \\bigl( 2\\tilde{y}^{(k+1)} - y^{(k)} \\bigr) \\Bigr), \\\\\n",
    "    \\bigl(x^{(k + 1)}, y^{(k + 1)}\\bigr) & = \\rho \\bigl(\\tilde{x}^{(k + 1)}, \\tilde{y}^{(k + 1)}\\bigr) + (1 - \\rho) \\bigl(x^{(k)}, y^{(k)}\\bigr) \n",
    "\\end{aligned}\n",
    "\\end{cases}\n",
    "\\label{eq:pdsm}\n",
    "\\end{equation}\n",
    "\n",
    "up to the desired accuracy for given initial data $x^{(0)}, y^{(0)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $\\tau, \\sigma > 0$ are parameters and $\\mathrm{prox}(\\cdot)$ denotes the proximal map, given by\n",
    "\\begin{equation*}\n",
    "\t\\mathrm{prox}_{J}(\\tilde{x}) = \\argmin_{x} \\frac{1}{2} \\norm{x - \\tilde{x}}^{2} + J(x),\n",
    "\\end{equation*}\n",
    "with $J$ being a proper, convex, and lower-semicontinuous function.\n",
    "\n",
    "Assuming that the saddle-point formulation admits solutions, so-called saddle points, and $\\tau \\sigma \\norm{K}^{2} < 1$ is satisfied, then the iteration converges to a saddle point at the rate $O(1/k)$.\n",
    "Here, $\\norm{K}$ denotes the operator norm of $K$.\n",
    "We refer e.g.\\ to X for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand\\measurementvec{b}\n",
    "\\newcommand\\measurementmtx{A}\n",
    "\\newcommand\\imagevec{v}\n",
    "\\newcommand\\psf{\\mathbf{h}}\n",
    "\\newcommand{\\crop}{\\mathbf{C}}\n",
    "\\newcommand\\full{\\mathbf{A}}\n",
    "\\newcommand{\\ftpsf}{\\mathbf{H}}$\n",
    "\n",
    "where $\\full^H$ is the adjoint of $\\full$, $\\measurementvec$ is the sensor measurement and $\\imagevec$ is the image of the scene.\n",
    "\n",
    "As input we consider a discrete (scalar) image sequence that is arranged as a vector $u^{\\delta} \\in \\R^{M}$ with $M = m n t$, where $n$ and $m$ denote the number of pixels in vertical, respectively, horizontal direction, and $t$ denotes the number of frames.\n",
    "We discretise \\eqref{eq:denoiseprob} as\n",
    "\\begin{equation}\n",
    "\t\\min_{u} \\; \\frac{1}{2} \\norm{Au - f}^{2} + \\alpha \\norm{D_{x} u}_{2, 1},\n",
    "\\label{eq:denoiseprobfd}\n",
    "\\end{equation}\n",
    "where $u \\in \\R^{M}$ is the unknown solution and $D_{x}: \\R^{M} \\to \\R^{M \\times 2}$ is a finite difference approximation of the spatial gradient operator.\n",
    "We use first-order forward differences with step size one and zero-Neumann boundary conditions, see e.g.\\ \\cite{ChaPoc16}, and obtain\n",
    "\\begin{equation*}\n",
    "\t\\norm{D_{x} u}_{2, 1} = \\sum_{j=1}^{M} \\sqrt{(D_{x} u)_{j, 1}^{2} + (D_{x} u)_{j, 2}^{2}}\n",
    "\\end{equation*}\n",
    "as a discrete (isotropic) approximation of the total variation \\eqref{eq:tv}.\n",
    "\n",
    "The problem \\eqref{eq:denoiseprobfd} can be written in the form of \\eqref{eq:minprob} with the operator $K: \\R^{M} \\to \\R^{M \\times 3}$ given by $Ku = (D_{x}u, D_{t}u)$ and\n",
    "\\begin{equation}\n",
    "\tg(u) = \\frac{1}{2} \\norm{Au - u^{\\delta}}^{2}, \\qquad f(\\mathbf{p}) = \\alpha \\norm{\\mathbf{p}}_{2, 1}.\n",
    "\\label{eq:fgdenoise}\n",
    "\\end{equation}\n",
    "Here, $\\mathbf{p} \\in \\R^{M \\times 2}$ and $q \\in \\R^{M}$.\\footnote{Even though uncommon in the literature, we will refrain from introducing new variables and instead use the same for both $f$ and $f^{*}$ for simplicity, since the dimensions are the same.}\n",
    "Since the function $f$ is separable, its Legendre--Fenchel conjugate is\n",
    "\\begin{equation}\n",
    "\tf^{*}(\\mathbf{p}) = \\delta_{\\{\\norm{\\cdot}_{2, \\infty} \\le \\alpha\\}}(\\mathbf{p}),\n",
    "\\label{eq:fstardenoise}\n",
    "\\end{equation}\n",
    "see e.g.\\ \\cite[Thm.~4.12]{Bec17}.\n",
    "Here, $\\delta_{\\{\\norm{\\cdot}_{2, \\infty} \\le \\alpha_{1}\\}}$ is the indicator function of the dual ball of size $\\alpha_{1}$.\n",
    "It is defined as\n",
    "\\begin{equation*}\n",
    "\t\\delta_{\\{\\norm{\\cdot}_{2, \\infty} \\le \\alpha\\}}(\\mathbf{p}) = \\begin{cases}\n",
    "\t\t0 & \\text{if} \\; \\norm{\\mathbf{p}_{j}} \\le \\alpha \\; \\text{for all $j$}, \\\\\n",
    "\t\t+\\infty & \\text{else},\n",
    "\t\\end{cases}\n",
    "\\end{equation*}\n",
    "where the index $j$ refers to the $j$-th row of a matrix.\n",
    "A corresponding saddle point formulation is then\n",
    "\\begin{equation}\n",
    "\t\\min_{u} \\max_{\\mathbf{p}} \\; \\langle D_{x} u, \\mathbf{p} \\rangle + g(u) - \\delta_{\\{\\norm{\\cdot}_{2, \\infty} \\le \\alpha\\}}(\\mathbf{p}).\n",
    "\\label{eq:saddlepointdenoise}\n",
    "\\end{equation}\n",
    "\n",
    "The proximal mappings in \\eqref{eq:pdhg} with respect to $g$ and $f^{*}$ can be computed in a straightforward manner.\n",
    "For the function $g$ in \\eqref{eq:fgdenoise} it is given by\n",
    "\\begin{equation*}\n",
    "\t\\hat{u} = \\mathrm{prox}_{\\frac{\\tau}{2} \\norm{A\\cdot - u^{\\delta}}^{2}}(\\tilde{u}) \\Leftrightarrow \\left(A^{*}A + \\frac{1}{\\tau} \\mathrm{Id}\\right)\\hat{u} = \\frac{1}{\\tau}\\tilde{u} + A^{*}u^{\\delta},\n",
    "\\end{equation*}\n",
    "since\n",
    "\\begin{equation*}\n",
    "    \\mathrm{prox}_{\\frac{\\tau}{2} \\norm{A\\cdot - u^{\\delta}}^{2}}(\\tilde{u}) = \\argmin_{u} \\frac{1}{2} \\norm{u - \\tilde{u}}^{2} + \\frac{\\tau}{2} \\norm{Au - u^{\\delta}}^{2}.\n",
    "\\end{equation*}\n",
    "Since $f^{*}$ is separable, the proximal mapping of \\eqref{eq:fstardenoise} can be computed separately for each dual variable $\\mathbf{p}$ and $q$, see e.g.\\ \\cite[Thm.~6.6]{Bec17}.\n",
    "They are given by the (pixelwise) orthogonal projection onto the $\\norm{\\cdot}_{2, \\infty}$-ball of size $\\alpha_{1}$ \\cite[Eq.~4.23]{ChaPoc11}, that is\n",
    "\\begin{equation*}\n",
    "\t\\mathbf{\\hat{p}} = \\Pi_{\\{\\norm{\\cdot}_{2, \\infty} \\le \\alpha\\}}(\\mathbf{\\tilde{p}}) \\Leftrightarrow \\hat{\\mathbf{p}}_{j} = \\frac{\\mathbf{\\tilde{p}}_{j}}{\\max\\{1, \\alpha^{-1} \\norm{\\mathbf{\\tilde{p}}_{j}}\\}}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand\\measurementvec{\\mathbf{b}}\n",
    "\\newcommand\\measurementmtx{\\mathbf{A}}\n",
    "\\newcommand\\imagevec{\\mathbf{v}}\n",
    "\\newcommand\\psf{\\mathbf{h}}\n",
    "\\newcommand{\\crop}{\\mathbf{C}}\n",
    "\\newcommand\\full{\\mathbf{A}}\n",
    "\\newcommand{\\ftpsf}{\\mathbf{H}}$\n",
    "Gradient descent is an iterative algorithm that finds the minimum of a convex function by following the slope \"downhill\" until it reaches a minimum. To solve the minimization problem\n",
    "\\begin{equation*}\n",
    "    \\operatorname{minimize} g(\\mathbf{x}),\n",
    "\\end{equation*}\n",
    "we find the gradient of $g$ wrt $\\mathbf{x}$, $\\nabla_\\mathbf{x} g$, and use the property that the gradient always points in the direction of steepest _ascent_. In order to minimize $g$, we go the other direction:\n",
    "$$\\begin{align*}\n",
    "    \\mathbf{x}_0 &= \\text{ initial guess} \\\\\n",
    "    \\mathbf{x}_{k+1} &\\leftarrow \\mathbf{x}_k - \\alpha_k \\nabla g(\\mathbf{x}_k),\n",
    "\\end{align*}$$\n",
    "where $\\alpha$ is a step size that determines how far in the descent direction we go at each iteration.\n",
    "\n",
    "Applied to our problem:\n",
    "$$\\begin{align*}\n",
    "    g(\\imagevec) &= \\frac{1}{2} \\|\\full\\imagevec- \\measurementvec \\|_2^2 \\\\\n",
    "    \\nabla_\\imagevec g(\\imagevec) &= \\full^H (\\full\\imagevec-\\measurementvec),\n",
    "\\end{align*}$$\n",
    "where $\\full^H$ is the adjoint of $\\full$, $\\measurementvec$ is the sensor measurement and $\\imagevec$ is the image of the scene.\n",
    "\n",
    "We use more efficient variants of this algorithm, like Nesterov Momentum and FISTA, both of which are shown below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preparing our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.fft as fft\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.sparse import spdiags\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code takes in two grayscale images: a point spread function (PSF) $\\texttt{psfname}$ and a sensor measurement $\\texttt{imgname}$. The images can be downsampled by a factor $f$, which must be a of the form $1/{2^k}$, for some non negative integer $k$ (typically between 1/2 and 1/8). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfname = \"./psf-2500.jpg\"\n",
    "imgname = \"./phone-10k.jpg\"\n",
    "#imgname = \"./backlight-5k.jpg\"\n",
    "#imgname = \"../test_images/google_chrome_logo_rgb.png\"\n",
    "psfname = \"./psf_sample.tif\"\n",
    "imgname = \"./rawdata_hand_sample.tif\"\n",
    "\n",
    "\n",
    "# Downsampling factor (used to shrink images)\n",
    "f = 1/4\n",
    "\n",
    "# Number of iterations\n",
    "iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata(show_im=True):\n",
    "    psf = Image.open(psfname)\n",
    "    psf = np.array(psf, dtype='float32')\n",
    "    #psf = np.sum(psf,axis=2)\n",
    "    data = Image.open(imgname)\n",
    "    data = np.array(data, dtype='float32')\n",
    "    #data = np.sum(data,axis=2)\n",
    "    \n",
    "    \"\"\"In the picamera, there is a non-trivial background \n",
    "    (even in the dark) that must be subtracted\"\"\"\n",
    "    bg = np.mean(psf[5:15,5:15]) \n",
    "    psf -= bg\n",
    "    data -= bg\n",
    "    \n",
    "    \"\"\"Resize to a more manageable size to do reconstruction on. \n",
    "    Because resizing is downsampling, it is subject to aliasing \n",
    "    (artifacts produced by the periodic nature of sampling). Demosaicing is an attempt\n",
    "    to account for/reduce the aliasing caused. In this application, we do the simplest\n",
    "    possible demosaicing algorithm: smoothing/blurring the image with a box filter\"\"\"\n",
    "    \n",
    "    def resize(img, factor):\n",
    "        num = int(-np.log2(factor))\n",
    "        for i in range(num):\n",
    "            img = 0.25*(img[::2,::2,...]+img[1::2,::2,...]+img[::2,1::2,...]+img[1::2,1::2,...])\n",
    "        return img    \n",
    "    \n",
    "    psf = resize(psf, f)\n",
    "    data = resize(data, f)\n",
    "    \n",
    "    \n",
    "    \"\"\"Now we normalize the images so they have the same total power. Technically not a\n",
    "    necessary step, but the optimal hyperparameters are a function of the total power in \n",
    "    the PSF (among other things), so it makes sense to standardize it\"\"\"\n",
    "    \n",
    "    psf /= np.linalg.norm(psf.ravel())\n",
    "    data /= np.linalg.norm(data.ravel())\n",
    "    \n",
    "    if show_im:\n",
    "        fig1 = plt.figure()\n",
    "        plt.imshow(psf, cmap='gray')\n",
    "        plt.title('PSF')\n",
    "        #display.display(fig1)\n",
    "        fig2 = plt.figure()\n",
    "        plt.imshow(data, cmap='gray')\n",
    "        plt.title('Raw data')\n",
    "        #display.display(fig2)\n",
    "        plt.show()\n",
    "\n",
    "    return psf, data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating convolutions using $\\texttt{fft}$\n",
    "We want to calculate convolutions efficiently. To do this, we use the \"fast fourier transform\" $\\texttt{fft2}$ which computes the Discrete Fourier Transform (DFT). The convolution theorem for DFTs only holds for circular convolutions. We can still recover a linear convolution by first padding the input images then cropping the output of the inverse DFT:\n",
    "\\begin{equation}\n",
    "h*x=\\mathcal{F}^{-1}[\\mathcal{F}[h]\\cdot\\mathcal{F}[x]] = \\texttt{crop}\\left[\\ \\texttt{DFT}^{-1}\\left\\{\\ \\texttt{DFT} [\\ \\texttt{pad}[h]\\ ]\\cdot\\texttt{DFT}[\\ \\texttt{pad}[x]\\ ]\\ \\right\\} \\ \\right]\n",
    "\\end{equation}\n",
    "\n",
    "Recovering the linear convolution correctly requires that we double the dimensions of our images. To take full advantage of the speed of the $\\texttt{fft2}$ algorithm, we actually pad $\\texttt{full_size}$, which is the nearest power of two that is larger than that size.\n",
    "\n",
    "We have chosen $\\texttt{full_size}$ in such a way that it provides enough padding to make circular and linear convolutions look the same <i>after being cropped back down to</i> $\\texttt{sensor_size}$. That way, the \"sensor crop\" due to the sensor's finite size and the \"fft crop\" above are the same, and we just need one crop function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with initialization, we compute $\\texttt{H} = \\texttt{fft2}(\\texttt{hpad})$ and $\\texttt{Hadj} = \\texttt{H}^*$, which are constant matrices that will be needed to calculate the action of $\\measurementmtx$ and $\\measurementmtx^H$ at every iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we must take into account one more practical difference. In imaging, we often treat the center of the image as the origin of the coordinate system. This is theoretically convenient, but fft algorithms assume the origin of the image is the top left pixel. The magnitude of the fft doesn't change because of this distinction, but the phase does, since it is sensitive to shifts in real space. An example with the simplest function, a delta function, is displayed below. In order to correct this problem, we use $\\texttt{ifftshift}$ to move the origin of an image to the top left corner and $\\texttt{fftshift}$ to move the origin from the top left corner to the center. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_shift():\n",
    "    delta = np.zeros((5,5))\n",
    "    delta[2][2] = 1\n",
    "    fft_mag = np.abs(fft.fft2(delta))\n",
    "    fft_arg = np.angle(fft.fft2(delta))\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "    fig.tight_layout()\n",
    "    ax[0].imshow(delta, cmap='gray')\n",
    "    ax[0].set_title('Delta function in \\n real space')\n",
    "\n",
    "    ax[1].imshow(fft_mag,vmin=-3,vmax=3,cmap='gray')\n",
    "    ax[1].set_title('Magnitude of FT of \\n a delta function')\n",
    "    \n",
    "    ax[2].imshow(fft_arg,vmin=-3,vmax=3,cmap='gray')\n",
    "    ax[2].set_title('Phase of FT of \\n delta function')\n",
    "    \n",
    "no_shift()   \n",
    "\n",
    "def shift():\n",
    "    delta = np.zeros((5,5))\n",
    "    delta[2][2] = 1\n",
    "    delta_shifted = fft.ifftshift(delta)\n",
    "    fft_mag = np.abs(fft.fft2(delta_shifted))\n",
    "    fft_arg = np.angle(fft.fft2(delta_shifted))\n",
    "    \n",
    "    fig2, ax2 = plt.subplots(nrows=1, ncols=3)\n",
    "    fig2.tight_layout()\n",
    "    ax2[0].imshow(delta_shifted, cmap='gray')\n",
    "    ax2[0].set_title('Delta function shifted in \\n real space')\n",
    "\n",
    "    ax2[1].imshow(fft_mag,vmin=-3,vmax=3,cmap='gray')\n",
    "    ax2[1].set_title('Magnitude of FT of a \\n shifted delta function')\n",
    "    \n",
    "    ax2[2].imshow(fft_arg,vmin=-3,vmax=3,cmap='gray')\n",
    "    ax2[2].set_title('Phase of FT of a \\n shifted delta function')\n",
    "    \n",
    "shift()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook and the ADMM notebook, we follow the following convention so we don't have to worry about this issue again:\n",
    "1. All images in _real_ space are stored with the origin in the center (so they can be displayed correctly)\n",
    "2. All images in _Fourier_ space are stored with the origin in the top left corner (so they can be used for processing correctly)\n",
    "3. The above rules mean that, to perform a convolution between two real space images $h$ and $x$, we do $$\\texttt{fftshift}( \\texttt{ifft} [\\texttt{fft}[ \\texttt{ifftshift}(h) \\cdot \\texttt{ifftshift}(x) ] ] )$$ instead of $$\\texttt{ifft}[\\texttt{fft}[h \\cdot x]]$$\n",
    "The rules imply that if we store the fourier transform of $h$ for future use, instead of storing $\\texttt{fft}[h]$, we store $\\texttt{fft}[\\texttt{ifftshift}(h)]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initMatrices(h):\n",
    "    pixel_start = (np.max(h) + np.min(h))/2\n",
    "    x = np.ones(h.shape)*pixel_start\n",
    "\n",
    "    init_shape = h.shape\n",
    "    padded_shape = [nextPow2(2*n - 1) for n in init_shape]\n",
    "    starti = (padded_shape[0]- init_shape[0])//2\n",
    "    endi = starti + init_shape[0]\n",
    "    startj = (padded_shape[1]//2) - (init_shape[1]//2)\n",
    "    endj = startj + init_shape[1]\n",
    "    hpad = np.zeros(padded_shape)\n",
    "    hpad[starti:endi, startj:endj] = h\n",
    "\n",
    "    H = fft.fft2(fft.ifftshift(hpad), norm=\"ortho\")\n",
    "    Hadj = np.conj(H)\n",
    "\n",
    "    def crop(X):\n",
    "        return X[starti:endi, startj:endj]\n",
    "\n",
    "    def pad(v):\n",
    "        vpad = np.zeros(padded_shape).astype(np.complex64)\n",
    "        vpad[starti:endi, startj:endj] = v\n",
    "        return vpad\n",
    "\n",
    "    utils = [crop, pad]\n",
    "    v = np.real(pad(x))\n",
    "    \n",
    "    return H, Hadj, v, utils\n",
    "\n",
    "def nextPow2(n):\n",
    "    return int(2**np.ceil(np.log2(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important step in Gradient Descent is calculating the gradient\n",
    "$$ \\nabla_\\imagevec \\  g(\\imagevec) = \\full^H (\\full\\imagevec-\\measurementvec)$$\n",
    "We do this in 2 steps:\n",
    "1. We compute the action of $\\full$ on $\\imagevec$, using $\\texttt{calcA}$\n",
    "2. We compute the action of $\\full^H$ on $\\texttt{diff} = \\texttt{Av-b}$ using $\\texttt{calcAHerm}$ <br/>\n",
    "\n",
    "Here, $\\texttt{vk}$ is the current padded estimate of the scene and $\\texttt{b}$ is the sensor measurement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(Hadj, H, vk, b, crop, pad):\n",
    "    Av = calcA(H, vk, crop)\n",
    "    diff = Av - b\n",
    "    return np.real(calcAHerm(Hadj, diff, pad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write $\\full$ as:\n",
    "$$ \\full\\imagevec \\iff \\mathrm{crop} \\left[ \\mathcal{F}^{-1} \\left\\{\\mathcal{F}(h) \\cdot \\mathcal{F}(v)\\right\\} \\right]$$\n",
    "In code, this becomes\n",
    "\\begin{align*} \n",
    "\\texttt{calcA}(\\texttt{vk}) & = \\texttt{crop}\\ (\\texttt{ifft}\\ (\\texttt{fft}(\\texttt{hpad}) \\cdot \\texttt{fft}(\\texttt{vk})\\ )\\  )\\\\\n",
    "& = \\texttt{crop}\\ (\\texttt{ifft}\\ (\\texttt{H} \\cdot \\texttt{Vk}))\n",
    "\\end{align*}\n",
    "where $\\cdot$ represents point-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcA(H, vk, crop):\n",
    "    Vk = fft.fft2(fft.ifftshift(vk))\n",
    "    return crop(fft.fftshift(fft.ifft2(H*Vk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first pad $\\texttt{diff}$ , giving us $\\texttt{xpad}$, then we take the 2D fourier transform, $\\texttt{X} = \\mathcal{F}(\\texttt{xpad})$. The action of the adjoint of $A$ is\n",
    "\n",
    "$$ A^H \\mathbf{x} \\iff \\mathcal{F}^{-1} \\left\\{ \\mathcal{F}(\\psf)^* \\cdot \\mathcal{F}( \\operatorname{pad}\\left[x\\right]) \\right\\}$$\n",
    "This becomes\n",
    "\\begin{align*}\n",
    "\\texttt{calcAHerm}(\\texttt{xk}) &= \\texttt{ifft}\\ (\\ (\\texttt{fft}(\\texttt{h}))^H \\cdot \\texttt{fft}\\ (\\texttt{pad}(\\texttt{diff}))\\ ) \\\\\n",
    "& = \\texttt{ifft}\\ (\\texttt{Hadj} \\cdot \\texttt{X})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAHerm(Hadj, diff, pad):\n",
    "    xpad = pad(diff)\n",
    "    X = fft.fft2(fft.ifftshift(xpad))\n",
    "    return fft.fftshift(fft.ifft2(Hadj*X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv2dfw(m, n):\n",
    "    v1 = -np.ones((m,))\n",
    "    v1[-1] = 0\n",
    "    v2 = np.ones((m,))\n",
    "    Dx = spdiags([v1, v2], [0, 1], m, m)\n",
    "    \n",
    "    v1 = -np.ones((n,))\n",
    "    v1[-1] = 0\n",
    "    v2 = np.ones((n,))\n",
    "    Dy = spdiags([v1, v2], [0, 1], n, n)\n",
    "    return Dx, Dy\n",
    "\n",
    "# Use function as:\n",
    "# n, m = image.shape\n",
    "# Dx, Dy = deriv2dfw(m, n)\n",
    "# gradx = image @ Dx.transpose())\n",
    "# grady = Dy @ image\n",
    "\n",
    "# And adjoint is:\n",
    "# - div(v) = v1 @ Dx + Dy.transpose() @ v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iter(H, Hadj, shape, crop, pad, iters):\n",
    "    v = np.random.random_sample(shape)\n",
    "    v = v / np.linalg.norm(v)\n",
    "    for k in range(iters):\n",
    "        y = calcA(H, v, crop)\n",
    "        w = np.real(calcAHerm(Hadj, y, pad))\n",
    "        L = np.dot(w.flatten(), v.flatten())\n",
    "        v = w / np.linalg.norm(w)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdsm(H, Hadj, v, b, crop, pad, tau, sigma, rho, gamma):\n",
    "\n",
    "    # Create finite difference operators.\n",
    "    n, m = v.shape\n",
    "    Dx, Dy = deriv2dfw(m, n)\n",
    "    \n",
    "    # Define prox operator for nonnegativity.\n",
    "    def non_neg(xi):\n",
    "        xi = np.maximum(xi, 0)\n",
    "        return xi\n",
    "        \n",
    "    # Initialise dual variables.\n",
    "    y1 = np.zeros_like(v)\n",
    "    y2 = np.zeros_like(v)\n",
    "    \n",
    "    \n",
    "    for k in range(iters):\n",
    "        # Update dual variable.\n",
    "        yt1 = y1 + sigma * v @ Dx.transpose()\n",
    "        yt2 = y2 + sigma * Dy @ v\n",
    "        norm = np.hypot(yt1, yt2)\n",
    "        yt1 = yt1 / np.maximum(1.0, norm / gamma)\n",
    "        yt2 = yt2 / np.maximum(1.0, norm / gamma)\n",
    "        \n",
    "        # Compute gradient.\n",
    "        gradient = grad(Hadj, H, v, b, crop, pad)\n",
    "        \n",
    "        # Update primal variable.\n",
    "        mdiv = (2 * yt1 - y1) @ Dx + Dy.transpose() @ (2 * yt2 - y2)\n",
    "        vt = non_neg(v - tau * gradient - tau * mdiv)\n",
    "        \n",
    "        # Extrapolation step.\n",
    "        v = rho * vt + (1 - rho) * v\n",
    "        y1 = rho * yt1 + (1 - rho) * y1\n",
    "        y2 = rho * yt2 + (1 - rho) * y2\n",
    "        \n",
    "        if k % 25 == 0:\n",
    "            image = non_neg(crop(v))\n",
    "            f = plt.figure()\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.title('Reconstruction after iteration {}'.format(k))\n",
    "            #display.display(f)\n",
    "            plt.show()\n",
    "            display.clear_output(wait=True)\n",
    "        \n",
    "    return non_neg(crop(v)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise operator and adjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images.\n",
    "psf, data = loaddata()\n",
    "\n",
    "# Compute operator.\n",
    "H, Hadj, v, utils = initMatrices(psf)\n",
    "crop = utils[0]\n",
    "pad = utils[1]\n",
    "\n",
    "# Estimate largest eigenvalue of operator.\n",
    "Lapprox = np.real(np.max(Hadj * H))\n",
    "L = power_iter(H, Hadj, v.shape, crop, pad, 100)\n",
    "print('Largest eigenvalue is approximately {:g}.'.format(Lapprox))\n",
    "print('Largest eigenvalue by power iteration. is approximately {:g}.'.format(L))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set regularisation parameter.\n",
    "gamma = 2e-7\n",
    "\n",
    "# Squared operator norm of finite difference gradient operator.\n",
    "# Upper bounded by 8 but can be set smaller.\n",
    "opnormsq = 2\n",
    "\n",
    "# Set parameters for algorithm.\n",
    "tau = 2 / L - 1\n",
    "sigma = (1 / tau - L / 2) / opnormsq\n",
    "rho = 2 - (L / 2) / (1 / tau - sigma * opnormsq)\n",
    "print('Parameters set to tau={:g}, sigma={:g}, rho={:g}.'.format(tau, sigma, rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_im = pdsm(H, Hadj, v, data, crop, pad, tau, sigma, rho, gamma)\n",
    "plt.imshow(final_im, cmap='gray')\n",
    "plt.title('Final reconstruction after {} iterations'.format(iters))\n",
    "display.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "img = Image.fromarray((150 * final_im / np.max(final_im)).astype(np.uint8), mode='L')\n",
    "img.save('results/result.png', 'PNG')\n",
    "img = Image.fromarray((150 * data / np.max(data)).astype(np.uint8), mode='L')\n",
    "img.save('results/raw.png', 'PNG')\n",
    "img = Image.fromarray((150 * psf / np.max(psf)).astype(np.uint8), mode='L')\n",
    "img.save('results/psf.png', 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
